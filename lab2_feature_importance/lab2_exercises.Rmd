---
title: "Lab feature importance"
output: html_document
---

```{r}
library(tidyverse)
library(dplyr)
wine <- read.table('./wine.txt', header = TRUE)
wine$class <- as.numeric(wine$class == 1)
```
We have explored the relationship between feature and target graphically, now we are going to measure it.

The deviance of a statistical model is comuted in the following way: -2 (LL(model) - LL(saturated model)). Where the saturated model has a perfect fit, with a parameter for each observation. The null deviance is the deviance for an intercept-only model. The deviance reduction is the proportional difference between the model deviance and the null deviance. It has a similar meaning as the R squared, amount of variance explained by the model.

2.1 Fit a logistic regression model on a data set and obtain the deviance and null.deviance from it.

```{r}

```

2.2 `glm` is a convenience wrapper over `glm.fit`, it allows you to feed it with a data frame, it will automatically add a column for the intercept and it gives the formula option so you can specify exactly what features to use. `glm.fit` however is easier to program with. Write a wrapper function that takes a data frame as input, adds a column ones for the intercept and saves it as a matrix. Save the class column in a vector. Then use `glm.fit` to obtain the deviance reduction.

```{r}

```

2.3 Apply this function to all the features of the wine data set. and save in a data frame.

```{r}

```

2.4 The object with relative information of the boosted model, shown in the slides, is saved in relative_information.Rdata (the object it loads is called rel_inf. Load it, join it to the data frame with deviance reduction and make a plot comparing the two.  

```{r}
load('./relative_information.Rdata')

```

2.5 Can you explain the relative information being higher than the deviance reduction for proline ?




